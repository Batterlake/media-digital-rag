{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import stamina\n",
    "from PIL import Image\n",
    "\n",
    "images_folder = Path(\"../data/jpeg\")\n",
    "folders = list(images_folder.glob(\"*\"))\n",
    "folders[0], folders[0].is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [pin]\n",
    "files = list(folders[0].iterdir())[:10]\n",
    "fig, axes = plt.subplots(1, len(files), figsize=(15, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = Image.open(files[i])\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(\n",
    "    url=\"http://ml.n19:6333\",\n",
    "    api_key=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colpali_engine.models import ColPali, ColPaliProcessor\n",
    "\n",
    "# Initialize ColPali model and processor\n",
    "model_name = \"vidore/colpali-v1.2\"  # Use the latest version available\n",
    "colpali_model = ColPali.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda:0\",  # Use \"cuda:0\" for GPU, \"cpu\" for CPU, or \"mps\" for Apple Silicon\n",
    ")\n",
    "colpali_processor = ColPaliProcessor.from_pretrained(\"vidore/colpali-v1.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"pdfs-2\"\n",
    "qdrant_client.delete_collection(collection_name=collection_name)\n",
    "if not qdrant_client.collection_exists(collection_name=collection_name):\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        on_disk_payload=True,  # store the payload on disk\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=128,\n",
    "            distance=models.Distance.COSINE,\n",
    "            on_disk=True,  # move original vectors to disk\n",
    "            multivector_config=models.MultiVectorConfig(\n",
    "                comparator=models.MultiVectorComparator.MAX_SIM\n",
    "            ),\n",
    "            quantization_config=models.BinaryQuantization(\n",
    "                binary=models.BinaryQuantizationConfig(\n",
    "                    always_ram=True  # keep only quantized vectors in RAM\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@stamina.retry(\n",
    "    on=Exception, attempts=3\n",
    ")  # retry mechanism if an exception occurs during the operation\n",
    "def upsert_to_qdrant(batch):\n",
    "    try:\n",
    "        qdrant_client.upsert(\n",
    "            collection_name=collection_name,\n",
    "            points=points,\n",
    "            wait=False,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error during upsert: {e}\")\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8  # Adjust based on your GPU memory constraints\n",
    "\n",
    "# Use tqdm to create a progress bar\n",
    "dataset = list(Path(\"../data/jpeg/\").rglob(\"*jpg\"))\n",
    "\n",
    "with tqdm(total=len(dataset), desc=\"Indexing Progress\") as pbar:\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        batch = dataset[i : i + batch_size]\n",
    "        \n",
    "        # The images are already PIL Image objects, so we can use them directly\n",
    "        images = [Image.open(el) for el in batch]\n",
    "\n",
    "        # Process and encode images\n",
    "        with torch.no_grad():\n",
    "            batch_images = colpali_processor.process_images(images).to(\n",
    "                colpali_model.device\n",
    "            )\n",
    "            image_embeddings = colpali_model(**batch_images)\n",
    "        # Prepare points for Qdrant\n",
    "        points = []\n",
    "        for j, embedding in enumerate(image_embeddings):\n",
    "            # Convert the embedding to a list of vectors\n",
    "            multivector = embedding.cpu().float().numpy().tolist()\n",
    "            image_name = Path(batch[j])\n",
    "            points.append(\n",
    "                models.PointStruct(\n",
    "                    id=i + j,  # we just use the index as the ID\n",
    "                    vector=multivector,  # This is now a list of vectors\n",
    "                    payload={\n",
    "                        \"file_id\": f\"previews/{image_name.parent.stem}\",\n",
    "                        \"page_id\": f\"{image_name.stem.split('-')[1]}\"\n",
    "                    },  # can also add other metadata/data\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Upload points to Qdrant\n",
    "        try:\n",
    "            upsert_to_qdrant(points)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during upsert: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(batch_size)\n",
    "\n",
    "print(\"Indexing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client.update_collection(\n",
    "    collection_name=collection_name,\n",
    "    optimizer_config=models.OptimizersConfigDiff(indexing_threshold=10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Как за 10 лет изменилось количество телепрограмм, привлекающих более 4-х млн. зрителей в Великобритании?\"\n",
    "# query_text = \"Как развивается геймдев в Москве?\"\n",
    "with torch.no_grad():\n",
    "    batch_query = colpali_processor.process_queries([query_text]).to(\n",
    "        colpali_model.device\n",
    "    )\n",
    "    query_embedding = colpali_model(**batch_query)\n",
    "query_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivector_query = query_embedding[0].cpu().float().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "search_result = qdrant_client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=multivector_query,\n",
    "    limit=10,\n",
    "    timeout=100,\n",
    "    search_params=models.SearchParams(\n",
    "        quantization=models.QuantizationSearchParams(\n",
    "            ignore=False,\n",
    "            rescore=True,\n",
    "            oversampling=2.0,\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "end_time = time.time()\n",
    "# Search in Qdrant\n",
    "search_result.points\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Search completed in {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = search_result.points[0].id\n",
    "Image.open(dataset[idx]).resize((320, 320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import request_with_image\n",
    "\n",
    "response = request_with_image(\n",
    "    query_text=query_text,\n",
    "    image_path=dataset[idx],\n",
    "    system_prompt=\"You are required to give a clear answer to the question posed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [pin]\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
